vocab_size: 32000

d_model: 768
num_heads: 12
num_layers: 12
max_seq_length: 256
dropout_rate: 0.1

learning_rate: 0.0005
batch_size: 16
num_epochs: 10
log_every: 200
seed: 1234